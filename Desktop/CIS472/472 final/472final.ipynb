{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8976731-54d9-46d4-8cd7-0bf15ba4b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1e9af48-d577-45b9-9f12-6440cc4ae395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in ./opt/anaconda3/lib/python3.9/site-packages (2.12.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in ./opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.12.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.54.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.32.0)\n",
      "Requirement already satisfied: setuptools in ./opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (63.4.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (16.0.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in ./opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (4.23.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (4.3.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in ./opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.4.12)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in ./opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in ./opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in ./opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in ./opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: packaging in ./opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in ./opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./opt/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in ./opt/anaconda3/lib/python3.9/site-packages (from jax>=0.3.15->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in ./opt/anaconda3/lib/python3.9/site-packages (from jax>=0.3.15->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: scipy>=1.7 in ./opt/anaconda3/lib/python3.9/site-packages (from jax>=0.3.15->tensorflow) (1.9.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in ./opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.20.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./opt/anaconda3/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in ./opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./opt/anaconda3/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in ./opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.6->jax>=0.3.15->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./opt/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63cc2d48-b533-4032-8bbf-d513b63715b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Importing necessary libraries\n",
    "\n",
    "# TensorFlow is our primary deep learning library\n",
    "import tensorflow as tf\n",
    "\n",
    "# Keras is TensorFlow's high-level API for deep learning\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "# Matplotlib is a graphing library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Numpy is used for handling arrays\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc94f503-3d60-4529-8a03-dd7b395e5811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load the MNIST dataset and perform preprocessing\n",
    "\n",
    "# The MNIST database contains 60,000 training images and 10,000 testing images of handwritten digits.\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# We can look at the shape of the dataset. Print the shape of x_train. It should show (60000, 28, 28), meaning there are 60,000 samples, each image is 28x28 pixels.\n",
    "print('x_train shape:', x_train.shape)\n",
    "\n",
    "# For feeding the data into our model, we want to flatten the images into a single dimension. We'll also normalize the pixel values from [0, 255] to [0, 1]. Neural networks work best with small input values.\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Each image is labeled with a digit from 0-9. We will one-hot encode these labels, i.e., a label of '3' will become the array [0, 0, 0, 1, 0, 0, 0, 0, 0, 0].\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f25da43-bdc8-4a1b-8230-2bcf1b54635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define the model architecture\n",
    "\n",
    "# We're using the Keras API to build the architecture for our CNN. We'll use a sequential model, which allows us to stack layers on top of each other. The input flows from top to bottom.\n",
    "model = Sequential()\n",
    "\n",
    "# The first layer will be a convolutional layer with 32 filters/kernels, each of size 3x3. We're using 'relu' (Rectified Linear Unit) as our activation function.\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "\n",
    "# Another convolutional layer with 64 filters of size 3x3 and 'relu' activation.\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Max pooling reduces the spatial dimensions, i.e., height and width, of our input. This makes our model less complex and speeds up the training process.\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Dropout is a regularization technique that randomly 'drops out', i.e., sets to zero, a number of output features of the layer during training. Here we drop out 25% of our layers.\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flatten the input. As we're using fully connected layers, we need to flatten our input into a single dimension.\n",
    "model.add(Flatten())\n",
    "\n",
    "# A fully connected layer with 128 units and 'relu' activation.\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Add another dropout layer, this time we drop out 50% of the neurons to prevent overfitting.\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# The final layer is a fully connected layer with 10 units (one for each class i.e., digit from 0 to 9) and 'softmax' activation. Softmax makes the output sum up to 1 so the output can be interpreted as probabilities. The model will then make its prediction based on which option has the highest probability.\n",
    "model.add(Dense(10, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24b8fc3e-a600-4725-acd2-e26f5bd6557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Compile the model\n",
    "\n",
    "# We're using categorical crossentropy as our loss function. This is the most common choice for classification. \n",
    "# A lower score indicates that the model is performing better.\n",
    "# 'accuracy' is the metrics used to measure performance of our model. \n",
    "# Adam is an optimization algorithm that can used instead of the classical stochastic gradient descent to update network weights iterative based on training data.\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ad03331-1c8d-47f8-ab94-bdb492f9d29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 121s 253ms/step - loss: 0.2447 - accuracy: 0.9252 - val_loss: 0.0543 - val_accuracy: 0.9824\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 130s 277ms/step - loss: 0.0851 - accuracy: 0.9750 - val_loss: 0.0387 - val_accuracy: 0.9854\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 125s 266ms/step - loss: 0.0650 - accuracy: 0.9796 - val_loss: 0.0376 - val_accuracy: 0.9868\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 115s 244ms/step - loss: 0.0506 - accuracy: 0.9840 - val_loss: 0.0306 - val_accuracy: 0.9902\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 115s 245ms/step - loss: 0.0455 - accuracy: 0.9862 - val_loss: 0.0289 - val_accuracy: 0.9901\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 116s 247ms/step - loss: 0.0380 - accuracy: 0.9879 - val_loss: 0.0306 - val_accuracy: 0.9899\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 111s 237ms/step - loss: 0.0339 - accuracy: 0.9893 - val_loss: 0.0270 - val_accuracy: 0.9909\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 128s 273ms/step - loss: 0.0306 - accuracy: 0.9903 - val_loss: 0.0268 - val_accuracy: 0.9919\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 125s 266ms/step - loss: 0.0291 - accuracy: 0.9901 - val_loss: 0.0255 - val_accuracy: 0.9925\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 126s 269ms/step - loss: 0.0257 - accuracy: 0.9915 - val_loss: 0.0264 - val_accuracy: 0.9916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb0acc02dc0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 5: Train the model\n",
    "\n",
    "# We're now ready to train our model. We're going to train over 10 epochs (an arbitrary choice). \n",
    "# At each epoch, the model will have seen every example in the dataset once. \n",
    "# The batch size defines the number of samples that will be propagated through the network and we've chosen a batch size of 128. \n",
    "# The higher the batch size, the more memory space you'll need. \n",
    "# Also, we pass our validation or test data to see the model's performance on it after every epoch.\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9df2c87f-22a8-451b-a45a-b1613e9e1a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.026431087404489517\n",
      "Test accuracy: 0.991599977016449\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Evaluate the model on the test data\n",
    "\n",
    "# Finally, we'll evaluate our model. \n",
    "# The model's performance is usually lower on the test data compared to the training data because the model is fit to the training data and not the test data. \n",
    "# We're interested in the accuracy of our model, so we'll print out the accuracy by evaluating our trained model on the test data.\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c15af93-b3a0-443a-9237-206e635310da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
